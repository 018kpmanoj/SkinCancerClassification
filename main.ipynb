{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743108c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.4.2-cp39-cp39-win_amd64.whl (10.5 MB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\karan\\.conda\\envs\\tf\\lib\\site-packages (from pandas) (1.22.3)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\karan\\.conda\\envs\\tf\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\karan\\.conda\\envs\\tf\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.4.2 pytz-2022.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "import numpy as np \n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from keras.applications import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e6ced05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model=MobileNetV2(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67b82014",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.40))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(7, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6be1a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:/Users/karan/Downloads/archive (1)/HAM10000_metadata.csv\")\n",
    "data['image_full_name']=data['image_id']+'.jpg'\n",
    "X=data[['image_full_name','dx','lesion_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5974d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_full_name</th>\n",
       "      <th>dx</th>\n",
       "      <th>lesion_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3729</th>\n",
       "      <td>ISIC_0029300.jpg</td>\n",
       "      <td>nv</td>\n",
       "      <td>HAM_0003914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5802</th>\n",
       "      <td>ISIC_0025880.jpg</td>\n",
       "      <td>nv</td>\n",
       "      <td>HAM_0005744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>ISIC_0024893.jpg</td>\n",
       "      <td>bkl</td>\n",
       "      <td>HAM_0002058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7449</th>\n",
       "      <td>ISIC_0033825.jpg</td>\n",
       "      <td>nv</td>\n",
       "      <td>HAM_0007552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7014</th>\n",
       "      <td>ISIC_0026633.jpg</td>\n",
       "      <td>nv</td>\n",
       "      <td>HAM_0007548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_full_name   dx    lesion_id\n",
       "3729  ISIC_0029300.jpg   nv  HAM_0003914\n",
       "5802  ISIC_0025880.jpg   nv  HAM_0005744\n",
       "529   ISIC_0024893.jpg  bkl  HAM_0002058\n",
       "7449  ISIC_0033825.jpg   nv  HAM_0007552\n",
       "7014  ISIC_0026633.jpg   nv  HAM_0007548"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd7442f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.1.1-cp39-cp39-win_amd64.whl (7.4 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\karan\\.conda\\envs\\tf\\lib\\site-packages (from scikit-learn) (1.22.3)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\karan\\.conda\\envs\\tf\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.1.0 scikit-learn-1.1.1 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "Y=X.pop('dx').to_frame()\n",
    "X_train, X_test, y_train, y_test   = train_test_split(X,Y, test_size=0.17, random_state=42)\n",
    "X_train,X_val,y_train,y_val        =train_test_split(X_train, y_train, test_size=0.17, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49357568",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.concat([X_train,y_train],axis=1)\n",
    "val=pd.concat([X_val,y_val],axis=1)\n",
    "test=pd.concat([X_test,y_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d31d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder= LabelEncoder()\n",
    "encoder.fit(val['dx'])\n",
    "name_as_indexes_train=encoder.transform(val['dx']) \n",
    "val['label']=name_as_indexes_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "418fd1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=LabelEncoder()\n",
    "encoder.fit(test['dx'])\n",
    "name_as_indexes_test=encoder.transform(test['dx']) \n",
    "test['label']=name_as_indexes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b090614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "train_generator = ImageDataGenerator(rescale = 1./255,\n",
    "                                     rotation_range=10,  \n",
    "                                     zoom_range = 0.1, \n",
    "                                     width_shift_range=0.0,  height_shift_range=0.00) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87855391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6898 validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data= train_generator.flow_from_dataframe(dataframe=train,x_col=\"image_full_name\",y_col=\"dx\",\n",
    "                                                batch_size=32,directory=\"C:/Users/karan/Downloads/archive (1)/HAM1000_images\",\n",
    "                                                shuffle=True,class_mode=\"categorical\",target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66bc9a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator=ImageDataGenerator(rescale = 1./255,rotation_range=10,  \n",
    "                                     zoom_range = 0.1, \n",
    "                                     width_shift_range=0.0,  height_shift_range=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15d20fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1703 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_data= test_generator.flow_from_dataframe(dataframe=test,x_col=\"image_full_name\",y_col=\"dx\",\n",
    "                                              directory=\"C:/Users/karan/Downloads/archive (1)/HAM1000_images\",\n",
    "                                              shuffle=False,batch_size=1,class_mode=None,target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d248d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1414 validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data=test_generator.flow_from_dataframe(dataframe=val,x_col=\"image_full_name\",y_col=\"dx\",\n",
    "                                            directory=\"C:/Users/karan/Downloads/archive (1)/HAM1000_images\",\n",
    "                                            batch_size=64,shuffle=False,class_mode=\"categorical\",target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17b33dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "learning_control = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=.5, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87e18fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam,SGD\n",
    "sgd = optimizers.SGD(learning_rate = 0.01, clipvalue = 0.5)\n",
    "model.compile(optimizer=sgd,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6ef962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karan\\AppData\\Local\\Temp\\ipykernel_14780\\1443149548.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(generator=train_data,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.6794 - accuracy: 0.7610WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "215/215 [==============================] - 899s 4s/step - loss: 0.6794 - accuracy: 0.7610 - val_loss: 2.6441 - val_accuracy: 0.6733 - lr: 0.0100\n",
      "Epoch 2/30\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.6078 - accuracy: 0.7820WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "215/215 [==============================] - 910s 4s/step - loss: 0.6078 - accuracy: 0.7820 - val_loss: 4.1304 - val_accuracy: 0.6733 - lr: 0.0100\n",
      "Epoch 3/30\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.5569 - accuracy: 0.8025WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "215/215 [==============================] - 906s 4s/step - loss: 0.5569 - accuracy: 0.8025 - val_loss: 4.1168 - val_accuracy: 0.6726 - lr: 0.0100\n",
      "Epoch 4/30\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.4985 - accuracy: 0.8217WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "215/215 [==============================] - 900s 4s/step - loss: 0.4985 - accuracy: 0.8217 - val_loss: 3.1883 - val_accuracy: 0.6761 - lr: 0.0100\n",
      "Epoch 5/30\n",
      "166/215 [======================>.......] - ETA: 3:15 - loss: 0.4560 - accuracy: 0.8364"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=train_data,\n",
    "                            steps_per_epoch=train_data.samples//train_data.batch_size,\n",
    "                            validation_data=val_data,\n",
    "                            verbose=1,\n",
    "                            validation_steps=val_data.samples//val_data.batch_size,\n",
    "                            epochs=30,callbacks=[learning_control])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8448754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
